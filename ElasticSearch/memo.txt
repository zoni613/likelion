


//전체 샤드 상태 보기
GET /_cat/shards/board-index?v

//현재 클러스터에 살아있는 노드, 할당 샤드, 역할 등 확인
GET /_cat/nodes?v


//현재 셋팅 확인
GET /board-index/_settings
GET board-index/_mapping

//현재 인덱스 데이터 보기
GET board-index/_search
{
  "query": {
    "match_all": {}
  }
}

//현재 인덱스의 데이터 1000개 보기
GET board-index/_search
{
  "size": 1000,
  "query": {
    "match_all": {}
  }
}

//spring이 포함된 데이터 검색
GET board-index/_search
{
  "query": {
    "match": {
      "title": "spring"
    }
  }
}


GET board-index/_search
{
  "query": {
    "term": {
      "_id": "12345"
    }
  }
}

//Elasticsearch 클러스터에 있는 모든 인덱스의 상태, 문서 수, 크기 등을 요약해서 보여줌
GET /_cat/indices?v

//검색결과 1건만 가져오기
GET /board-index/_search?size=1

//id가 5인 데이터 삭제
DELETE board-index/_doc/5

//인덱스 삭제
DELETE board-index/


//분석기 테스트 기능
POST board-index/_analyze
{
  "text": "웹소켓와 파이썬의 예제 0"
}



//중간검색,초성, 자동완성포함 인덱스
PUT /board-index
{
  "settings": {

    "number_of_shards": 3,  //샤드 3개
    "number_of_replicas": 1,  //복제본 1개
    "index.max_ngram_diff": 8,  // 8글자를 각 ngram_filter 에서 최대 허용치 (max - min)  간극  -> "min_gram과 max_gram의 차이가 8까지 허용된다"는 뜻
                                    //"hello" → ngram(2~10) 결과   ->  he, el, ll, lo, hel, ell, llo, hell, ello, hello
                                     //간격이 크면 성능에 무리가 감
                                     // 예를 들어 "elasticsearch" (13글자)에서
                                     // min_gram: 2, max_gram: 3 → 조각 2~3글자만 만듦(적당)
                                     // min_gram: 2, max_gram: 10 → 2~10글자 모든 조합을 만듦(수백 개 생성)

    "analysis": {                       // 문장 분석기 설정 영역

      "filter": {                        // 🔹 [1]"filter 정의 영역" (단어 단위로 잘라낸 후 그 단어들을 어떻게 변형할지 정의하는 영역)

        "autocomplete_filter": {           // 내가 정의한 filter 이름
          "type": "edge_ngram",            // 🔍 자동완성용 필터: 앞에서부터 잘게 자름   예) 예: "spring" → "s", "sp", "spr", "spri", "sprin", "spring"
          "min_gram": 1,                    // 최소 몇 글자부터 자를지
          "max_gram": 20                    // 최대 몇 글자까지 자를지
        },

        //중간 문자 검색
        "ngram_filter": {
          "type": "ngram",
          "min_gram": 2,
          "max_gram": 10
        },

        //초성
        "chosung_filter": {
           "type": "hanhinsam_chosung"
        }

      },

      "analyzer": {                        // 실제로 문장을 분석할 때 사용할 분석기를 정의하는 곳 (위에서 정의할 필터를 사용하는 곳)

        "autocomplete_analyzer": {         // 내가 정의한 커스텀 분석기 이름
          "type": "custom",                // 내가 만든 커스텀 분석기 사용
          "tokenizer": "standard",         // 단어 단위로 분리  (공백, 특수문자 등 기준으로 단어 분리)
          "filter": [                       // 🔸 [2] "어떤 필터들을 사용할지 나열"
            "lowercase",                   // 소문자로 통일
            "autocomplete_filter"         // 위에서 정의한 필터를 사용 (접두사 조각 생성)  예) 예: "spring" → "s", "sp", "spr", "spri", "sprin", "spring"
          ]
        },

         "ngram_analyzer": {
           "type": "custom",
           "tokenizer": "standard",
           "filter": ["lowercase", "ngram_filter"]
         },

        "chosung_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "chosung_filter"
          ]
        }

      }
    }



  },

  "mappings": {
    "properties": {

      "_class": {                          //spring data elasticsearch에서 객체를 저장할 때 자동으로 추가하는 메타데이터
        "type": "keyword",
        "index": false,                   // 🔒 저장은 되지만 검색/정렬에서 제외
        "doc_values": false              // 🔒 집계에도 사용 안 함
      },

      "content": {
        "type": "text",                     //  ✅ 자연어 문장을 검색할 수 있는 필드라는 의미
        "analyzer": "autocomplete_analyzer", // ✅ (인덱싱용)  텍스트를 어떻게 쪼개서 색인(저장)할지  (위 settings -> analysis -> analyzer 에서 만든 분석기 사용)
        "search_analyzer": "standard",       // ✅ (검색용)  검색 시에는 어떻게 분석해서 찾을지

        "fields": {

          "chosung": {                        // 초성 검색 전용 필드
            "type": "text",
            "analyzer": "chosung_analyzer"      // ✅ 초성검색
          },

          "keyword": {
            "type": "keyword",
            "ignore_above": 256          // ✅ 256자 이상인 문자열은 인덱싱하지 않겠다는 설정  (일반적으로 Elasticsearch의 성능 보호를 위한 제한)
          },

          "ngram": {
            "type": "text",
            "analyzer": "ngram_analyzer"
          }

        }
      },


      "title": {
        "type": "text",
        "analyzer": "autocomplete_analyzer",
        "search_analyzer": "standard",
        "fields": {

          "chosung": {                               // 초성 검색 전용 필드
            "type": "text",
            "analyzer": "chosung_analyzer"
          },

          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          },

            "ngram": {
            "type": "text",
            "analyzer": "ngram_analyzer"
          }
        }
      },


      "id": {
        "type": "text",                   // ⚠️ 원래는 keyword로 쓰는 게 더 좋음 (식별자니까)
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },

      "userId": {
        "type": "long"                    // 사용자 ID (정수형 필터/정렬 가능)
      },

      "username": {
        "type": "text",                   // 사용자 이름 (검색용)
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256          // 정렬/집계용
          }
        }
      },

      "created_date": {
        "type": "text",                   // ⚠️ 날짜로 쓸 거면 나중에 date로 바꾸는 게 좋음
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },

      "updated_date": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      }

    }
  }
}

